---
title: Conjoint experiments
format: html
bibliography: conjoint.bib
---

```{css, echo=FALSE}
.table {
  font-size: .8em;
}
```


```{r}
#| include: false
# options(marginaleffects_print_digits = getOption("digits"))
options(width = 1000)
# library(cjoint)
# dat = data.table(immigrationconjoint)[, .(
#   choice = Chosen_Immigrant,
#   job = Job,
#   language = `Language Skills`,
#   respondent = CaseID,
#   task = contest_no,
#   profile)]
# levels(dat$language) = gsub(" +", " ", trimws(gsub("English", "", levels(dat$language))))
```

A forced-choice conjoint experiment is a research methodology used in many fields such as marketing and political science to understand how people make decisions between "profiles" characterized by multiple "attributes." In this type of experiment, participants are presented with a series of choices between different products, services, or scenarios. Each option is described by a set of attributes (e.g., price, quality, brand, features), and the levels of these attributes are varied randomly across the options presented.

Consider an experiment where researchers ask survey respondents "to act as immigration officials and to decide which of a pair of immigrants they would choose for admission" [@HaiHopYam2014]. They display a table in which each column represents a distinct immigrant "profile" with randomized attributes. For example:

```{r}
#| echo: false
#| tbl-cap: A single forced-choice task in a conjoint experiment. The survey respondent must choose one of the two profiles before seeing a second task.
library(tinytable)
tmp <- data.frame(
  "Attributes" = c("Language Skills", "Job"),
  `Profile 1` = c("Fluent in English", "Construction worker"),
  `Profile 2` = c("Broken English", "Nurse"),
  check.names = FALSE
)
tt(tmp)
```

The survey respondent has the "task" of choosing one of the two profiles. Then, the researchers display a new task, including profiles with different randomized attributes, and the respondent chooses again. 

By analyzing the choices made by participants, researchers can estimate the relative importance of different attributes in the decision-making process. 

The rest of this vignette shows how to use the `marginaleffects` package to estimate the main quantities of the quantities of interest in such experiments.


# Data

To illustrate, we use data published alongside the *Political Analysis* article by @HaiHopYam2014. In this experiment, each survey respondent $i$ receives several tasks $k$, in which they select one of two profiles $j$, characterized by attributes $l$.

For simplicity, we consider a subset of the data with 5 tasks per respondent, 2 profiles per task, and 2 attributes per profile. The data is structured in "long" format, with one respondent-task-profile combination per row. 

These are the entries for survey respondent number 4:

```{r}
library(marginaleffects)
library(data.table)
library(tinytable)

dat <- readRDS(url("https://marginaleffects.com/data/conjoint_immigration.rds", "rb"))

dat[dat$respondent == 4, ]
```

The `choice` column indicates if the profile in each row was selected by the respondent.

These data are structured in what could be called a "long" format. Later on in the vignette, it will be useful to have information in a "wide" format, with new columns indicating what attributes characterized every profile in each task. To create these new columns, we use `dcast()` from the `data.table` package. This function is analogous to `reshape()` in base `R` or `pivot_wider()` in the `tidyverse`:

```{r}
dat <- data.table(dat)
wide <- dcast(dat, 
  respondent + task ~ profile,
  value.var = c("language", "job")
)
dat <- merge(dat, wide)
```

We now have new columns called `language_1` and `language_2` indicating the language skills of profiles 1 and 2 respectively in each task.

```{r}
dat[dat$respondent == 4, ]
```


# Marginal means

As described by @LeeHobTil2020, a "marginal mean describes the level of favorability toward profiles that have a particular feature level, ignoring all other features." 

To compute marginal means, we proceed in 3 steps:

1. Estimate a regression model with `choice` as outcome and the attributes of interest as predictors. 
2. Compute the predicted (i.e., fitted) values for each row in the original dataset. 
3. Marginalize (average) those predictions with respect to the variable of interest.

To illustrate, we estimate a linear regression model with interactions between the `language` and `job` variables:

```{r}
mod <- lm(choice ~ job * language, data = dat)
```

Then, we use the `avg_predictions()` function to compute and marginalize predicted values. Note that we use the `vcov` argument to report clustered standard errors at the respondent-level.

```{r}
avg_predictions(mod, by = "language", vcov = ~respondent)
```

The results above suggests that, ignoring (or averaging over) the `job` attribute, the "fluent" English speakers are chosen more often than profiles with other `language` values.

## Hypothesis tests

Using the `hypothesis` argument, we can easily conduct various null hypothesis tests on the estimated marginal means. For example, is the probability of choosing a "fluent" profile equal to the probability of choosing a "tried but unable" profile?


```{r}
avg_predictions(mod, 
  hypothesis = "b1 = b3",
  by = "language", 
  vcov = ~respondent)
```

Is the difference in probabiliy between "fluent" and "broken" equal to the difference in probability between "tried but unable" and "used interpreter"?

```{r}
avg_predictions(mod, 
  hypothesis = "b1 - b2 = b3 - b4",
  by = "language", 
  vcov = ~respondent)
```

## Subgroups

Modifying the `by` allows analysts to report marginal means for different subgroups of their data, and `newdata` can be used to exclude uninteresting profiles:

```{r}
avg_predictions(mod, 
  by = c("language", "job"),
  newdata = subset(dat, job %in% c("doctor", "gardener")),
  vcov = ~respondent)
```


# Average Marginal Component Effects

Average Marginal Component Effects (AMCE) are defined and analyzed in @HaiHopYam2014. Roughly speaking, they can be viewed as the average effects of changing one attribute on choice, while holding all other attributes of the profile constant. To compute an AMCE, we can proceed in 4 steps:

1. Create a dataset A where the `language` column is equal to "fluent English" in every row.
2. Create a dataset B where the `language` column is equal to "broken English" in every row.
3. Compute predicted (fitted) values for every row in datasets A and B.
4. Compute the average difference between predicted values in the two datasets.

This can be achieved easily using the `avg_comparisons()` function from the `marginaleffects` package:

```{r}
avg_comparisons(mod, variables = "language", vcov = ~respondent)
```

## Empirical vs. balanced grid

In the example above, `avg_predictions()` marginalized across the realized distribution of attributes observed in the actual dataset. An alternative would be to marginalzed over a perfectly balanced ("uniform") grid of treatment conditions. Of course, empirical and uniform grids will yield nearly identical results if the sample is large and randomization successful.

The uniform approach is the default in the `amce()` function from the `cjoint` package, and the behavior can be replicated using the `datagrid()` function and the `newdata` argument in `avg_comparisons()`:

```{r}
#| message: false
#| warning: false
library(cjoint)

amce_results <- amce(
  choice ~ language * job,
  data = dat,
  cluster = TRUE,
  respondent.id = "respondent")

summary(amce_results)$amce |> subset(Attribute == "language")

avg_comparisons(mod,
  newdata = datagrid(FUN_factor = unique, FUN_character = unique),
  variables = "language",
  vcov = ~respondent)
```



#  Average Feature Choice Probability

@Abr2024 introduce an alternative estimand for forced-choice conjoint experiments: the Average Feature Choice Probability (AFCP). The main difference between AMCE and AFCP lies in their approach to handling attribute comparisons.

AMCE incorporates comparisons and averages over both direct and indirect attribute comparisons, potentially considering information about irrelevant attributes, thus imposing a strong transitivity assumption. In some cases, AMCE can suggest positive effects even when, in direct comparisons, respondents are on average less likely to choose a profile with the feature of interest over the baseline. In contrast, AFCP focuses solely on direct comparisons between attributes, offering a more accurate representation of respondents' direct preferences without the influence of irrelevant attributes.

To estimate AFCP, we once again start by estimating a linear regression model. This time, the model is even more flexible. Specifically, the model allows the effect of language skills in the first profile to depend on the value of language skills in the second profile. Likewise, other attributes can influence the probability of selection differently based on attributes in the comparison profile. To achieve this, we interact `language_1` with `language_2`, and `job_1` with `job_2`. 

Moreover, since the data is in "long" format, with one profile per row, we must also allow each variable to have different coefficients based on `profile` number: the effect of `language_1` on the probability of selection is obviously different for `profile=1` and for `profile=2`. Indeed, when `profile=1` the `language_1` column records the profile's own language skills. When `profile=2`, the same column records the alternative profile's language skills.

Thankfully, it is trivial to allow this flexibility by interacting the attributes with the `profile` variable:

```{r}
mod = lm(choice ~ factor(profile) * (language_1 * language_2 + job_1 * job_2), dat)
```

As explained above and detailed in @Abr2024, the AFCP is a choice pair-specific quantity. This means that we need to average predictions (fitted values) across covariates, within each unique pair of attributes of interest. To allow this, we create a new variable called `alternative`:^[The `fifelse()` function from `data.table` preserves factor levels, but not the standard `ifelse()`.]

```{r}
dat$alternative <- fifelse(
  dat$language == dat$language_1, 
  dat$language_2, 
  dat$language_1
)
```

This table shows the language skills and job of both profiles in the first task faced by respondent number 4. The `alternative` column simply shows the language skills of the alternative profile within each task:

```{r}
subset(dat,
  task == 1 & respondent == 4, 
  select = c("respondent", "task", "profile", "job", "language", "alternative")) |>
  tt()
```

Now we compute the AFCP by averaging fitted values by unique pairs of attributes for language (the combination of `language` and `alternative`). Since we are not interested comparison pairs where both profiles have the same language skills, we use the `subset` to supply an appropriate grid.


```{r}
p <- avg_predictions(mod, 
  by = c("language", "alternative"), 
  newdata = subset(dat, language != alternative),
  vcov = ~respondent)
```

Display the results in a nice `tinytable`:

```{r}
library(tinytable)
idx <- which(p$alternative == "fluent")
print(p, "tinytable") |> style_tt(i = idx, background = "pink")
```

The results in pink are the same as those produced by [the `afcp` package:](https://github.com/astrezhnev/afcp)

```{r}
#| warning: false
#| message: false
library(afcp)

afcp_results <- afcp(
  amce_results,
  respondent.id = "respondent",
  task.id = "task",
  profile.id = "profile",
  attribute = "language")

afcp_results$afcp
```

## Hypothesis tests


A powerful feature of `marginaleffects` is that all its functions include a `hypothesis` argument which can be used to conduct hypothesis tests on arbitrary functions of estimates. For example, let's compute the AFCP for a subset of profile comparisons:

```{r}
p <- avg_predictions(mod, 
  by = c("language", "alternative"), 
  newdata = subset(dat, language != alternative & alternative == "fluent"),
  vcov = ~respondent)
p
```

Now, let's say we would like to test if any of the pairwise comparisons between AFCP is different from zero. All we need to do is use add a `hypothesis="pairwise"` argument:


```{r}
avg_predictions(mod, 
  hypothesis = "pairwise",
  by = c("language", "alternative"), 
  newdata = subset(dat, language != alternative & alternative == "fluent"),
  vcov = ~respondent)
```

