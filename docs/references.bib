@article{knuth84,
  author = {Knuth, Donald E.},
  title = {Literate Programming},
  year = {1984},
  issue_date = {May 1984},
  publisher = {Oxford University Press, Inc.},
  address = {USA},
  volume = {27},
  number = {2},
  issn = {0010-4620},
  url = {https://doi.org/10.1093/comjnl/27.2.97},
  doi = {10.1093/comjnl/27.2.97},
  journal = {Comput. J.},
  month = may,
  pages = {97–111},
  numpages = {15}
}

@article{RafGre2020,
  title={Semantic and cognitive tools to aid statistical science: replace confidence and significance by compatibility and surprise},
  author={Rafi, Zad and Greenland, Sander},
  journal={BMC medical research methodology},
  volume={20},
  pages={1--13},
  year={2020},
  publisher={Springer}
}

@article{Rot2021,
  title={Rothman Responds to “Surprise!”},
  author={Rothman, Kenneth J},
  journal={American Journal of Epidemiology},
  volume={190},
  number={2},
  pages={194--195},
  year={2021},
  publisher={Oxford University Press}
}

@article{ColEdwGre2021,
  title={Surprise!},
  author={Cole, Stephen R and Edwards, Jessie K and Greenland, Sander},
  journal={American Journal of Epidemiology},
  volume={190},
  number={2},
  pages={191--193},
  year={2021},
  publisher={Oxford University Press}
}


 @article{AngBat2022, title={A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification}, url={http://arxiv.org/abs/2107.07511}, DOI={10.48550/arXiv.2107.07511}, abstractNote={Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on. This hands-on introduction is aimed to provide the reader a working understanding of conformal prediction and related distribution-free uncertainty quantification techniques with one self-contained document. We lead the reader through practical theory for and examples of conformal prediction and describe its extensions to complex machine learning tasks involving structured outputs, distribution shift, time-series, outliers, models that abstain, and more. Throughout, there are many explanatory illustrations, examples, and code samples in Python. With each code sample comes a Jupyter notebook implementing the method on a real-data example; the notebooks can be accessed and easily run using our codebase.}, note={arXiv:2107.07511 [cs, math, stat]}, number={arXiv:2107.07511}, publisher={arXiv}, author={Angelopoulos, Anastasios N. and Bates, Stephen}, year={2022}, month={Sep} }
 

@article{Din2023, title={Class-Conditional Conformal Prediction With Many Classes}, url={http://arxiv.org/abs/2306.09335}, DOI={10.48550/arXiv.2306.09335}, abstractNote={Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-chosen probability. In many classification problems, we would like to obtain a stronger guarantee -- that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. Existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction, which clusters together classes that have “similar” conformal scores and then performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set size metrics.}, note={arXiv:2306.09335 [cs, stat]}, number={arXiv:2306.09335}, publisher={arXiv}, author={Ding, Tiffany and Angelopoulos, Anastasios N. and Bates, Stephen and Jordan, Michael I. and Tibshirani, Ryan J.}, year={2023}, month={Jun} }
